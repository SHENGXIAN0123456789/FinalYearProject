# Job Market Analysis System

A comprehensive job market analysis system that scrapes job postings from major Malaysian job portals (JobStreet and RiceBowl), processes the data, and provides analytical insights through a web dashboard.

## ğŸ“‹ Project Overview

This Final Year Project consists of three main components:
- **Web Scraper**: Automated data collection from job portals using Scrapy
- **Data Processing Pipeline**: Cleaning, normalization, and database insertion
- **Web Dashboard**: Flask-based analytics interface for job market insights

## ğŸ¯ Features

- **Automated Job Scraping**: Collect job postings from JobStreet and RiceBowl
- **Data Cleaning & Processing**: Standardize job categories, skills, locations, and types
- **Database Storage**: PostgreSQL database with optimized schema
- **Analytics Dashboard**: Interactive web interface for data visualization
- **Job Market Insights**: Analysis by location, categories, skills, and job types
- **Date Range Filtering**: Historical job market trend analysis

## ğŸ› ï¸ Prerequisites

Before running this project, ensure you have the following installed:

- **Python 3.11+** - Programming language runtime
- **PostgreSQL 16.8+** - Database server
- **Git** - Version control system
- **pip** - Python package manager

### System Requirements
- Windows/Linux/macOS
- 4GB+ RAM recommended
- 2GB+ free disk space

## ğŸ“¦ Installation

### 1. Clone the Repository
```bash
git clone <repository-url>
cd FinalYearProject
```

### 2. Database Setup
1. Install and start PostgreSQL server
2. Create a database named `FYP`:
```sql
CREATE DATABASE FYP;
```
3. Update database credentials in `.env` file (create if doesn't exist):
```env
DB_USER=postgres
DB_PASSWORD=your_password
DB_HOST=localhost
DB_PORT=5432
DB_NAME=FYP
SECRET_KEY=your_secret_key_here
```

### 3. Initialize Database Schema
```bash
cd data/db/init
python init_db.py
```

### 4. Install Dependencies

#### For Web Scraper:
```bash
cd myScraper
pip install -r requirements.txt
```

#### For Data Processing:
```bash
cd data
pip install -r requirements.txt
```

#### For Web Dashboard:
```bash
cd web
pip install -r requirements.txt
```

## ğŸš€ Usage

### 1. Data Collection (Web Scraping)
```bash
cd myScraper
# Scrape JobStreet
scrapy crawl jobstreet
# Scrape RiceBowl
scrapy crawl ricebowl
```

### 2. Data Processing
```bash
cd data/cleaner
# Clean JobStreet data
python js_cleaner.py
# Clean RiceBowl data
python rb_cleaner.py
```

### 3. Database Insertion
```bash
cd data/db/insert
python insert.py
```

### 4. Run Web Dashboard
```bash
cd web
python run.py
```
Access the dashboard at `http://localhost:5000`

## ğŸ“ Project Structure

```
FinalYearProject/
â”œâ”€â”€ myScraper/              # Scrapy web scraping project
â”‚   â”œâ”€â”€ myScraper/
â”‚   â”‚   â”œâ”€â”€ spiders/        # Spider implementations
â”‚   â”‚   â”œâ”€â”€ items.py        # Data models
â”‚   â”‚   â””â”€â”€ settings.py     # Scrapy configuration
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ data/                   # Data processing pipeline
â”‚   â”œâ”€â”€ cleaner/           # Data cleaning scripts
â”‚   â”œâ”€â”€ db/                # Database operations
â”‚   â”‚   â”œâ”€â”€ init/          # Database initialization
â”‚   â”‚   â””â”€â”€ insert/        # Data insertion scripts
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ web/                   # Flask web application
â”‚   â”œâ”€â”€ templates/         # HTML templates
â”‚   â”œâ”€â”€ static/           # CSS, JS, images
â”‚   â”œâ”€â”€ app.py            # Flask application factory
â”‚   â”œâ”€â”€ routes.py         # API and page routes
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

### Scraping Configuration
- API keys and proxy settings in `myScraper/myScraper/settings.py`
- Spider-specific settings in individual spider files

### Database Configuration
- Connection settings via environment variables
- Schema initialization scripts in `data/db/init/`

### Web Application Configuration
- Flask settings in `web/app.py`
- Environment variables in `.env` file

## ğŸ“Š Data Sources

- **JobStreet Malaysia**: Job postings from major Malaysian job portal
- **RiceBowl**: Technology-focused job postings

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/new-feature`)
3. Commit your changes (`git commit -am 'Add new feature'`)
4. Push to the branch (`git push origin feature/new-feature`)
5. Create a Pull Request

## ğŸ“ License

This project is developed as part of a Final Year Project for academic purposes.

## âš ï¸ Disclaimer

This tool is designed for educational and research purposes. Please ensure compliance with the terms of service of the websites being scraped and respect robots.txt files.

## ğŸ†˜ Troubleshooting

### Common Issues:
1. **Database Connection Error**: Verify PostgreSQL is running and credentials are correct
2. **Scraping Blocked**: Check proxy settings and rate limiting
3. **Module Import Error**: Ensure all requirements are installed in correct virtual environment

For additional support, please check the issue tracker or contact the development team.